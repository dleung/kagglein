{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>educationNum</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>284582</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>160187</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-spouse-absent</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>Jamaica</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>209642</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>45781</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>14084</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>42</td>\n",
       "      <td>Private</td>\n",
       "      <td>159449</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>5178</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>280464</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>30</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>141297</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>India</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>23</td>\n",
       "      <td>Private</td>\n",
       "      <td>122272</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>205019</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>121772</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>?</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>245487</td>\n",
       "      <td>7th-8th</td>\n",
       "      <td>4</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>25</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>176756</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>186824</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>28887</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>43</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>292175</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>193524</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>302146</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>35</td>\n",
       "      <td>Federal-gov</td>\n",
       "      <td>76845</td>\n",
       "      <td>9th</td>\n",
       "      <td>5</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>117037</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Transport-moving</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>2042</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>59</td>\n",
       "      <td>Private</td>\n",
       "      <td>109015</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>56</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>216851</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>19</td>\n",
       "      <td>Private</td>\n",
       "      <td>168294</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>54</td>\n",
       "      <td>?</td>\n",
       "      <td>180211</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>South</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>367260</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>49</td>\n",
       "      <td>Private</td>\n",
       "      <td>193366</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>23</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>190709</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32530</th>\n",
       "      <td>30</td>\n",
       "      <td>?</td>\n",
       "      <td>33811</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32531</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>204461</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32532</th>\n",
       "      <td>54</td>\n",
       "      <td>Private</td>\n",
       "      <td>337992</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>Japan</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32533</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>179137</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32534</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>325033</td>\n",
       "      <td>12th</td>\n",
       "      <td>8</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32535</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>160216</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>55</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32536</th>\n",
       "      <td>30</td>\n",
       "      <td>Private</td>\n",
       "      <td>345898</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32537</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>139180</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>15020</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32538</th>\n",
       "      <td>71</td>\n",
       "      <td>?</td>\n",
       "      <td>287372</td>\n",
       "      <td>Doctorate</td>\n",
       "      <td>16</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32539</th>\n",
       "      <td>45</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>252208</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Separated</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32540</th>\n",
       "      <td>41</td>\n",
       "      <td>?</td>\n",
       "      <td>202822</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Separated</td>\n",
       "      <td>?</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32541</th>\n",
       "      <td>72</td>\n",
       "      <td>?</td>\n",
       "      <td>129912</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>?</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32542</th>\n",
       "      <td>45</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>119199</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32543</th>\n",
       "      <td>31</td>\n",
       "      <td>Private</td>\n",
       "      <td>199655</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Other</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32544</th>\n",
       "      <td>39</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>111499</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32545</th>\n",
       "      <td>37</td>\n",
       "      <td>Private</td>\n",
       "      <td>198216</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32546</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>260761</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32547</th>\n",
       "      <td>65</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>99359</td>\n",
       "      <td>Prof-school</td>\n",
       "      <td>15</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>1086</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32548</th>\n",
       "      <td>43</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>255835</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Other-relative</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32549</th>\n",
       "      <td>43</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>27242</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Craft-repair</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32550</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>34066</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Amer-Indian-Eskimo</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32551</th>\n",
       "      <td>43</td>\n",
       "      <td>Private</td>\n",
       "      <td>84661</td>\n",
       "      <td>Assoc-voc</td>\n",
       "      <td>11</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Sales</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32552</th>\n",
       "      <td>32</td>\n",
       "      <td>Private</td>\n",
       "      <td>116138</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32553</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>321865</td>\n",
       "      <td>Masters</td>\n",
       "      <td>14</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32554</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>310152</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32555</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32556</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32557</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32558</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32559</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&gt;50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32560 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age         workclass  fnlwgt     education  educationNum  \\\n",
       "0       50  Self-emp-not-inc   83311     Bachelors            13   \n",
       "1       38           Private  215646       HS-grad             9   \n",
       "2       53           Private  234721          11th             7   \n",
       "3       28           Private  338409     Bachelors            13   \n",
       "4       37           Private  284582       Masters            14   \n",
       "5       49           Private  160187           9th             5   \n",
       "6       52  Self-emp-not-inc  209642       HS-grad             9   \n",
       "7       31           Private   45781       Masters            14   \n",
       "8       42           Private  159449     Bachelors            13   \n",
       "9       37           Private  280464  Some-college            10   \n",
       "10      30         State-gov  141297     Bachelors            13   \n",
       "11      23           Private  122272     Bachelors            13   \n",
       "12      32           Private  205019    Assoc-acdm            12   \n",
       "13      40           Private  121772     Assoc-voc            11   \n",
       "14      34           Private  245487       7th-8th             4   \n",
       "15      25  Self-emp-not-inc  176756       HS-grad             9   \n",
       "16      32           Private  186824       HS-grad             9   \n",
       "17      38           Private   28887          11th             7   \n",
       "18      43  Self-emp-not-inc  292175       Masters            14   \n",
       "19      40           Private  193524     Doctorate            16   \n",
       "20      54           Private  302146       HS-grad             9   \n",
       "21      35       Federal-gov   76845           9th             5   \n",
       "22      43           Private  117037          11th             7   \n",
       "23      59           Private  109015       HS-grad             9   \n",
       "24      56         Local-gov  216851     Bachelors            13   \n",
       "25      19           Private  168294       HS-grad             9   \n",
       "26      54                 ?  180211  Some-college            10   \n",
       "27      39           Private  367260       HS-grad             9   \n",
       "28      49           Private  193366       HS-grad             9   \n",
       "29      23         Local-gov  190709    Assoc-acdm            12   \n",
       "...    ...               ...     ...           ...           ...   \n",
       "32530   30                 ?   33811     Bachelors            13   \n",
       "32531   34           Private  204461     Doctorate            16   \n",
       "32532   54           Private  337992     Bachelors            13   \n",
       "32533   37           Private  179137  Some-college            10   \n",
       "32534   22           Private  325033          12th             8   \n",
       "32535   34           Private  160216     Bachelors            13   \n",
       "32536   30           Private  345898       HS-grad             9   \n",
       "32537   38           Private  139180     Bachelors            13   \n",
       "32538   71                 ?  287372     Doctorate            16   \n",
       "32539   45         State-gov  252208       HS-grad             9   \n",
       "32540   41                 ?  202822       HS-grad             9   \n",
       "32541   72                 ?  129912       HS-grad             9   \n",
       "32542   45         Local-gov  119199    Assoc-acdm            12   \n",
       "32543   31           Private  199655       Masters            14   \n",
       "32544   39         Local-gov  111499    Assoc-acdm            12   \n",
       "32545   37           Private  198216    Assoc-acdm            12   \n",
       "32546   43           Private  260761       HS-grad             9   \n",
       "32547   65  Self-emp-not-inc   99359   Prof-school            15   \n",
       "32548   43         State-gov  255835  Some-college            10   \n",
       "32549   43  Self-emp-not-inc   27242  Some-college            10   \n",
       "32550   32           Private   34066          10th             6   \n",
       "32551   43           Private   84661     Assoc-voc            11   \n",
       "32552   32           Private  116138       Masters            14   \n",
       "32553   53           Private  321865       Masters            14   \n",
       "32554   22           Private  310152  Some-college            10   \n",
       "32555   27           Private  257302    Assoc-acdm            12   \n",
       "32556   40           Private  154374       HS-grad             9   \n",
       "32557   58           Private  151910       HS-grad             9   \n",
       "32558   22           Private  201490       HS-grad             9   \n",
       "32559   52      Self-emp-inc  287927       HS-grad             9   \n",
       "\n",
       "              marital-status         occupation    relationship  \\\n",
       "0         Married-civ-spouse    Exec-managerial         Husband   \n",
       "1                   Divorced  Handlers-cleaners   Not-in-family   \n",
       "2         Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "3         Married-civ-spouse     Prof-specialty            Wife   \n",
       "4         Married-civ-spouse    Exec-managerial            Wife   \n",
       "5      Married-spouse-absent      Other-service   Not-in-family   \n",
       "6         Married-civ-spouse    Exec-managerial         Husband   \n",
       "7              Never-married     Prof-specialty   Not-in-family   \n",
       "8         Married-civ-spouse    Exec-managerial         Husband   \n",
       "9         Married-civ-spouse    Exec-managerial         Husband   \n",
       "10        Married-civ-spouse     Prof-specialty         Husband   \n",
       "11             Never-married       Adm-clerical       Own-child   \n",
       "12             Never-married              Sales   Not-in-family   \n",
       "13        Married-civ-spouse       Craft-repair         Husband   \n",
       "14        Married-civ-spouse   Transport-moving         Husband   \n",
       "15             Never-married    Farming-fishing       Own-child   \n",
       "16             Never-married  Machine-op-inspct       Unmarried   \n",
       "17        Married-civ-spouse              Sales         Husband   \n",
       "18                  Divorced    Exec-managerial       Unmarried   \n",
       "19        Married-civ-spouse     Prof-specialty         Husband   \n",
       "20                 Separated      Other-service       Unmarried   \n",
       "21        Married-civ-spouse    Farming-fishing         Husband   \n",
       "22        Married-civ-spouse   Transport-moving         Husband   \n",
       "23                  Divorced       Tech-support       Unmarried   \n",
       "24        Married-civ-spouse       Tech-support         Husband   \n",
       "25             Never-married       Craft-repair       Own-child   \n",
       "26        Married-civ-spouse                  ?         Husband   \n",
       "27                  Divorced    Exec-managerial   Not-in-family   \n",
       "28        Married-civ-spouse       Craft-repair         Husband   \n",
       "29             Never-married    Protective-serv   Not-in-family   \n",
       "...                      ...                ...             ...   \n",
       "32530          Never-married                  ?   Not-in-family   \n",
       "32531     Married-civ-spouse     Prof-specialty         Husband   \n",
       "32532     Married-civ-spouse    Exec-managerial         Husband   \n",
       "32533               Divorced       Adm-clerical       Unmarried   \n",
       "32534          Never-married    Protective-serv       Own-child   \n",
       "32535          Never-married    Exec-managerial   Not-in-family   \n",
       "32536          Never-married       Craft-repair   Not-in-family   \n",
       "32537               Divorced     Prof-specialty       Unmarried   \n",
       "32538     Married-civ-spouse                  ?         Husband   \n",
       "32539              Separated       Adm-clerical       Own-child   \n",
       "32540              Separated                  ?   Not-in-family   \n",
       "32541     Married-civ-spouse                  ?         Husband   \n",
       "32542               Divorced     Prof-specialty       Unmarried   \n",
       "32543               Divorced      Other-service   Not-in-family   \n",
       "32544     Married-civ-spouse       Adm-clerical            Wife   \n",
       "32545               Divorced       Tech-support   Not-in-family   \n",
       "32546     Married-civ-spouse  Machine-op-inspct         Husband   \n",
       "32547          Never-married     Prof-specialty   Not-in-family   \n",
       "32548               Divorced       Adm-clerical  Other-relative   \n",
       "32549     Married-civ-spouse       Craft-repair         Husband   \n",
       "32550     Married-civ-spouse  Handlers-cleaners         Husband   \n",
       "32551     Married-civ-spouse              Sales         Husband   \n",
       "32552          Never-married       Tech-support   Not-in-family   \n",
       "32553     Married-civ-spouse    Exec-managerial         Husband   \n",
       "32554          Never-married    Protective-serv   Not-in-family   \n",
       "32555     Married-civ-spouse       Tech-support            Wife   \n",
       "32556     Married-civ-spouse  Machine-op-inspct         Husband   \n",
       "32557                Widowed       Adm-clerical       Unmarried   \n",
       "32558          Never-married       Adm-clerical       Own-child   \n",
       "32559     Married-civ-spouse    Exec-managerial            Wife   \n",
       "\n",
       "                     race     sex  capital-gain  capital-loss  hours-per-week  \\\n",
       "0                   White    Male             0             0              13   \n",
       "1                   White    Male             0             0              40   \n",
       "2                   Black    Male             0             0              40   \n",
       "3                   Black  Female             0             0              40   \n",
       "4                   White  Female             0             0              40   \n",
       "5                   Black  Female             0             0              16   \n",
       "6                   White    Male             0             0              45   \n",
       "7                   White  Female         14084             0              50   \n",
       "8                   White    Male          5178             0              40   \n",
       "9                   Black    Male             0             0              80   \n",
       "10     Asian-Pac-Islander    Male             0             0              40   \n",
       "11                  White  Female             0             0              30   \n",
       "12                  Black    Male             0             0              50   \n",
       "13     Asian-Pac-Islander    Male             0             0              40   \n",
       "14     Amer-Indian-Eskimo    Male             0             0              45   \n",
       "15                  White    Male             0             0              35   \n",
       "16                  White    Male             0             0              40   \n",
       "17                  White    Male             0             0              50   \n",
       "18                  White  Female             0             0              45   \n",
       "19                  White    Male             0             0              60   \n",
       "20                  Black  Female             0             0              20   \n",
       "21                  Black    Male             0             0              40   \n",
       "22                  White    Male             0          2042              40   \n",
       "23                  White  Female             0             0              40   \n",
       "24                  White    Male             0             0              40   \n",
       "25                  White    Male             0             0              40   \n",
       "26     Asian-Pac-Islander    Male             0             0              60   \n",
       "27                  White    Male             0             0              80   \n",
       "28                  White    Male             0             0              40   \n",
       "29                  White    Male             0             0              52   \n",
       "...                   ...     ...           ...           ...             ...   \n",
       "32530  Asian-Pac-Islander  Female             0             0              99   \n",
       "32531               White    Male             0             0              60   \n",
       "32532  Asian-Pac-Islander    Male             0             0              50   \n",
       "32533               White  Female             0             0              39   \n",
       "32534               Black    Male             0             0              35   \n",
       "32535               White  Female             0             0              55   \n",
       "32536               Black    Male             0             0              46   \n",
       "32537               Black  Female         15020             0              45   \n",
       "32538               White    Male             0             0              10   \n",
       "32539               White  Female             0             0              40   \n",
       "32540               Black  Female             0             0              32   \n",
       "32541               White    Male             0             0              25   \n",
       "32542               White  Female             0             0              48   \n",
       "32543               Other  Female             0             0              30   \n",
       "32544               White  Female             0             0              20   \n",
       "32545               White  Female             0             0              40   \n",
       "32546               White    Male             0             0              40   \n",
       "32547               White    Male          1086             0              60   \n",
       "32548               White  Female             0             0              40   \n",
       "32549               White    Male             0             0              50   \n",
       "32550  Amer-Indian-Eskimo    Male             0             0              40   \n",
       "32551               White    Male             0             0              45   \n",
       "32552  Asian-Pac-Islander    Male             0             0              11   \n",
       "32553               White    Male             0             0              40   \n",
       "32554               White    Male             0             0              40   \n",
       "32555               White  Female             0             0              38   \n",
       "32556               White    Male             0             0              40   \n",
       "32557               White  Female             0             0              40   \n",
       "32558               White    Male             0             0              20   \n",
       "32559               White  Female         15024             0              40   \n",
       "\n",
       "             country income  \n",
       "0      United-States  <=50K  \n",
       "1      United-States  <=50K  \n",
       "2      United-States  <=50K  \n",
       "3               Cuba  <=50K  \n",
       "4      United-States  <=50K  \n",
       "5            Jamaica  <=50K  \n",
       "6      United-States   >50K  \n",
       "7      United-States   >50K  \n",
       "8      United-States   >50K  \n",
       "9      United-States   >50K  \n",
       "10             India   >50K  \n",
       "11     United-States  <=50K  \n",
       "12     United-States  <=50K  \n",
       "13                 ?   >50K  \n",
       "14            Mexico  <=50K  \n",
       "15     United-States  <=50K  \n",
       "16     United-States  <=50K  \n",
       "17     United-States  <=50K  \n",
       "18     United-States   >50K  \n",
       "19     United-States   >50K  \n",
       "20     United-States  <=50K  \n",
       "21     United-States  <=50K  \n",
       "22     United-States  <=50K  \n",
       "23     United-States  <=50K  \n",
       "24     United-States   >50K  \n",
       "25     United-States  <=50K  \n",
       "26             South   >50K  \n",
       "27     United-States  <=50K  \n",
       "28     United-States  <=50K  \n",
       "29     United-States  <=50K  \n",
       "...              ...    ...  \n",
       "32530  United-States  <=50K  \n",
       "32531  United-States   >50K  \n",
       "32532          Japan   >50K  \n",
       "32533  United-States  <=50K  \n",
       "32534  United-States  <=50K  \n",
       "32535  United-States   >50K  \n",
       "32536  United-States  <=50K  \n",
       "32537  United-States   >50K  \n",
       "32538  United-States   >50K  \n",
       "32539  United-States  <=50K  \n",
       "32540  United-States  <=50K  \n",
       "32541  United-States  <=50K  \n",
       "32542  United-States  <=50K  \n",
       "32543  United-States  <=50K  \n",
       "32544  United-States   >50K  \n",
       "32545  United-States  <=50K  \n",
       "32546         Mexico  <=50K  \n",
       "32547  United-States  <=50K  \n",
       "32548  United-States  <=50K  \n",
       "32549  United-States  <=50K  \n",
       "32550  United-States  <=50K  \n",
       "32551  United-States  <=50K  \n",
       "32552         Taiwan  <=50K  \n",
       "32553  United-States   >50K  \n",
       "32554  United-States  <=50K  \n",
       "32555  United-States  <=50K  \n",
       "32556  United-States   >50K  \n",
       "32557  United-States  <=50K  \n",
       "32558  United-States  <=50K  \n",
       "32559  United-States   >50K  \n",
       "\n",
       "[32560 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Imports\n",
    "%matplotlib inline\n",
    "import pandas\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from sklearn_pandas import DataFrameMapper, cross_val_score\n",
    "from sklearn import linear_model\n",
    "import json\n",
    "import time\n",
    "\n",
    "#Preview Data\n",
    "df_orig = pandas.read_csv('/Users/dleung/www/mlcompetition/training.tsv', sep='\\t')\n",
    "df_orig.columns = ['age', 'workclass', 'fnlwgt', 'education', 'educationNum', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'country', 'income']\n",
    "df_orig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Preprocessing classes\n",
    "# Split the categories into it's own columns\n",
    "class OneHotEncoder:       \n",
    "    def fit(self, data, columns):        \n",
    "        m, n = np.shape(data)\n",
    "        dat_matrix = []\n",
    "        category_map = {}\n",
    "        idx = 0\n",
    "        for column in columns:\n",
    "            distinct_categories = list(set(data[column].values.tolist()))\n",
    "            \n",
    "            for category in distinct_categories:\n",
    "                category_map[column + '_' + category] = idx\n",
    "                idx += 1\n",
    "            \n",
    "            category_map[column + '_unknown'] = idx\n",
    "            idx += 1\n",
    "                \n",
    "        for index, row in data.iterrows():\n",
    "            row_dict = {}\n",
    "            for k, v in category_map.items():\n",
    "                row_dict[k] = 0\n",
    "            for column in columns:\n",
    "                value = row[column]\n",
    "\n",
    "                if row_dict.has_key(column + '_' + value):\n",
    "                    row_dict[column + '_' + value] = 1\n",
    "                else:\n",
    "                    row_dict[column + '_unknown'] = 1\n",
    "\n",
    "            dat_matrix.append(row_dict)\n",
    "\n",
    "        column_names = [None] * (1 + max(category_map.values()))\n",
    "        for k, v in category_map.items():\n",
    "            column_names[v] = k\n",
    "        \n",
    "        self.category_map = category_map\n",
    "\n",
    "        return pandas.DataFrame(dat_matrix, columns=column_names)\n",
    "    \n",
    "    def test(self, data, columns):\n",
    "        m, n = np.shape(data)\n",
    "        dat_matrix = []\n",
    "        \n",
    "        for index, row in data.iterrows():\n",
    "            row_dict = {}\n",
    "            for k, v in self.category_map.items():\n",
    "                row_dict[k] = 0\n",
    "            for column in columns:\n",
    "                value = row[column]\n",
    "\n",
    "                if row_dict.has_key(column + '_' + value):\n",
    "                    row_dict[column + '_' + value] = 1\n",
    "                else:\n",
    "                    row_dict[column + '_unknown'] = 1\n",
    "\n",
    "            dat_matrix.append(row_dict)\n",
    "\n",
    "        column_names = [None] * (1 + max(self.category_map.values()))\n",
    "        for k, v in self.category_map.items():\n",
    "            column_names[v] = k\n",
    "\n",
    "        return pandas.DataFrame(dat_matrix, columns=column_names)\n",
    "        \n",
    "    \n",
    "# Class to scale feature set with zero mean and unit variance\n",
    "class GaussianScalar:\n",
    "    def fit(self, data, columns):\n",
    "        dat_matrix = {}\n",
    "        column_names = []\n",
    "        \n",
    "        self.var = {}\n",
    "        self.mean = {}\n",
    "        for column in columns:\n",
    "            rows = []\n",
    "            \n",
    "            col_var = np.std(data[column])\n",
    "            col_mean = np.mean(data[column])\n",
    "            \n",
    "            self.var[column] = col_var\n",
    "            self.mean[column] = col_mean\n",
    "            \n",
    "            for row in data[column]:\n",
    "                rows.append((row - col_mean) / (col_var))\n",
    "            \n",
    "            dat_matrix[column + \"_scalar\"] = rows\n",
    "            column_names.append(column + \"_scalar\")\n",
    "        \n",
    "        return pandas.DataFrame(dat_matrix, columns=column_names)\n",
    "    def test(self, data, columns):\n",
    "        dat_matrix = {}\n",
    "        column_names = []\n",
    "        \n",
    "        for column in columns:\n",
    "            rows = []\n",
    "            \n",
    "            for row in data[column]:\n",
    "                rows.append((row - self.mean[column]) / (self.var[column]))\n",
    "                \n",
    "            dat_matrix[column + \"_scalar\"] = rows\n",
    "            column_names.append(column + \"_scalar\")\n",
    "        \n",
    "        return pandas.DataFrame(dat_matrix, columns=column_names)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataset Methods\n",
    "def loadDataSet(data_columns, rows=None):\n",
    "    df_orig = pandas.read_csv('/Users/dleung/www/mlcompetition/training.tsv', sep='\\t')\n",
    "    df_orig.columns = data_columns\n",
    "    if rows != None:\n",
    "        df_orig = df_orig[0:rows]\n",
    "        \n",
    "    df_orig = df_orig.iloc[np.random.permutation(len(df_orig))]\n",
    "    return df_orig.reset_index(drop=True)\n",
    "\n",
    "def loadTestSet(data_columns):\n",
    "    df_test = pandas.read_csv('/Users/dleung/www/mlcompetition/test.tsv', sep='\\t', header=None)\n",
    "    df_test.columns = data_columns\n",
    "    return df_test\n",
    "\n",
    "def printValidationResults(pred, real):\n",
    "    df = pandas.DataFrame(np.asarray(pred), columns=['pred'])\n",
    "    df.insert(1, 'actual', real)\n",
    "\n",
    "    correct = float(len(df[df.pred == df.actual].index))\n",
    "    percent_correct = correct / len(df.index)\n",
    "\n",
    "    print('=========validation results============')\n",
    "    print('correct: %02f' % correct)\n",
    "    print('total: %02f' % len(df.index))\n",
    "    print('%% correct: %05f' % percent_correct)\n",
    "    \n",
    "\n",
    "# Load Train, Validation, and Test Sets\n",
    "data_columns = ['age', 'workclass', 'fnlwgt', 'education', 'educationNum', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'country', 'income']\n",
    "test_data_columns = ['age', 'workclass', 'fnlwgt', 'education', 'educationNum', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'country']\n",
    "\n",
    "categorical_columns = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'country']\n",
    "scalar_columns = ['age', 'hours-per-week', 'capital-gain', 'capital-loss']\n",
    "\n",
    "percent_train = 0.8\n",
    "rows = None\n",
    "max_cycles = 2000\n",
    "\n",
    "df_orig = loadDataSet(data_columns, rows)\n",
    "\n",
    "categoryEncoder = OneHotEncoder()\n",
    "scalarEncoder = GaussianScalar()\n",
    "\n",
    "categorical_df = categoryEncoder.fit(df_orig, categorical_columns)\n",
    "scalar_df = scalarEncoder.fit(df_orig, scalar_columns)\n",
    "\n",
    "y_df = pandas.DataFrame(np.where(df_orig.income == \"<=50K\", 0, 1), columns=['label'])\n",
    "data_df =  pandas.concat([categorical_df, scalar_df], axis=1)\n",
    "\n",
    "m, _ = np.shape(data_df)\n",
    "training_m_rows = int(percent_train * m)\n",
    "\n",
    "# Generate Training data\n",
    "train_data_df = data_df[0:training_m_rows]\n",
    "train_y_df = y_df[0:training_m_rows]\n",
    "\n",
    "# Generating Validation data\n",
    "validation_data_df = data_df[training_m_rows:-1].reset_index(drop=True)\n",
    "validation_y_df = y_df[training_m_rows:-1].reset_index(drop=True)\n",
    "\n",
    "# Generating TEST data\n",
    "df_test = loadTestSet(test_data_columns)\n",
    "test_categorical_df = categoryEncoder.test(df_test, categorical_columns)\n",
    "test_scalar_df = scalarEncoder.test(df_test, scalar_columns)\n",
    "test_data_df = pandas.concat([test_categorical_df, test_scalar_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "def sigmoid(z):\n",
    "    return 1.0 / (1 + np.exp(-z))\n",
    "\n",
    "# Batch gradient ascent\n",
    "def gradAscent(data_orig, y_orig, max_cycles=1000, alpha=0.1, error_delta=0.005):\n",
    "    data_df = data_orig.copy()\n",
    "    y_df = y_orig.copy()\n",
    "\n",
    "    m, n = np.shape(data_df)\n",
    "    data_df.insert(0, 'zeroth_feature', np.ones((m, 1)))\n",
    "    n = n + 1\n",
    "    data = np.mat(data_df)\n",
    "    y = np.mat(y_df)\n",
    "    error_sum = float(\"inf\")\n",
    "    \n",
    "    weights = np.ones((n, 1))\n",
    "    errors_x = []\n",
    "    errors_y = []\n",
    "    iteration = 0\n",
    "    while (abs(error_sum) > error_delta) and (iteration < max_cycles):\n",
    "        if (iteration % 1000 == 0):\n",
    "            print(\"Iteration #\" + str(iteration))\n",
    "        # Gradient of sigmoid function\n",
    "        error = y - sigmoid(data * weights)\n",
    "\n",
    "        error_sum = np.sum(error)\n",
    "\n",
    "        errors_x.append(iteration)\n",
    "        errors_y.append(error_sum)\n",
    "\n",
    "        weights = weights + alpha * data.transpose() * error\n",
    "        iteration += 1\n",
    "    return weights, (errors_x, errors_y)\n",
    "\n",
    "# Stochastic Gradient Ascent\n",
    "def stocGradAscent(data_orig, y_orig):\n",
    "    data_df = data_orig.copy()\n",
    "    y_df = y_orig.copy()\n",
    "\n",
    "    m, n = np.shape(data_df)\n",
    "    data_df.insert(0, 'zeroth_feature', np.ones((m, 1)))\n",
    "    n = n + 1\n",
    "    data = np.mat(data_df)\n",
    "    y = np.mat(y_df)\n",
    "    \n",
    "    alpha = 0.01\n",
    "    \n",
    "    weights = np.ones((n, 1))\n",
    "    errors_x = []\n",
    "    errors_y = []\n",
    "    \n",
    "    for i in range(m):\n",
    "        h = sigmoid(data[i] * weights)\n",
    "        error = (y[i] - h)[0,0]\n",
    "\n",
    "        if (i % 1000 == 0):\n",
    "            print(\"Iteration Number: \" + str(i))\n",
    "        errors_x.append(i)\n",
    "        errors_y.append(error)\n",
    "\n",
    "        weights = weights + alpha * data[i] * error\n",
    "    return weights, (errors_x, errors_y)\n",
    "\n",
    "# Minibatch Gradient Ascent\n",
    "def minibatchstocGradAscent1(data_orig, y_orig, numIter=150, alpha=0.01):\n",
    "    data_df = data_orig.copy()\n",
    "    y_df = y_orig.copy()\n",
    "\n",
    "    m, n = np.shape(data_df)\n",
    "    data_df.insert(0, 'zeroth_feature', np.ones((m, 1)))\n",
    "    n = n + 1\n",
    "    data = np.mat(data_df)\n",
    "    y = np.mat(y_df)\n",
    "    \n",
    "    weights = np.ones((1, n))\n",
    "    errors_x = []\n",
    "    errors_y = []\n",
    "    \n",
    "    for j in range(numIter):\n",
    "        data_index = range(m)\n",
    "        \n",
    "        if (j % 1000 == 0):\n",
    "            print(\"Iteration Number: \" + str(j))\n",
    "        \n",
    "        for i in range(m):\n",
    "            alpha = 4 / (1.0 + j + 1) + 0.01\n",
    "            rand_index = int(random.uniform(0, len(data_index)))\n",
    "            \n",
    "            h = sigmoid(data[rand_index] * weights.transpose())\n",
    "            error = (y[rand_index] - h)[0,0]\n",
    "            \n",
    "            weights = weights + alpha * data[rand_index] * error \n",
    "            del(data_index[rand_index])\n",
    "            \n",
    "        errors_x.append(j)\n",
    "        errors_y.append(error)\n",
    "        \n",
    "    return weights, (errors_x, errors_y)\n",
    "\n",
    "def classifyVector(test_data_df_orig, weights):\n",
    "    data_df = test_data_df_orig.copy()\n",
    "    \n",
    "    m, n = np.shape(data_df)\n",
    "    data_df.insert(0, 'zeroth_feature', np.ones((m, 1)))\n",
    "    \n",
    "    sig_y = sigmoid(data_df.values * weights)\n",
    "\n",
    "    sig_y_df = pandas.DataFrame(np.asarray(sig_y.transpose())[0], columns=['y_pred'])\n",
    "    return pandas.DataFrame(np.where(sig_y_df['y_pred'] >=  0.5, 1, 0), columns=['pred']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #0\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaUAAAEPCAYAAADiVdsmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10ee6dc10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cycles: 1000\n",
      "final error: -4571.850235\n",
      "=========validation results============\n",
      "correct: 0.000000\n",
      "total: 6511.000000\n",
      "% correct: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Perform Logistic Regression\n",
    "weights, errors = gradAscent(train_data_df, train_y_df, alpha=0.001)\n",
    "\n",
    "plt.plot(errors[0], errors[1])\n",
    "plt.ylabel('total error')\n",
    "plt.xlabel('cycles')\n",
    "plt.show()\n",
    "\n",
    "print(\"cycles: %s\" % len(errors[0]))\n",
    "print(\"final error: %05f\" % errors[1][-1])\n",
    "\n",
    "# Test on Validation set.  This is pretty accurate to actual test submission\n",
    "validation_y_pred = classifyVector(validation_data_df, weights)\n",
    "\n",
    "printValidationResults(validation_y_pred, validation_y_df)\n",
    "\n",
    "y_test = pandas.DataFrame(np.asarray(classifyVector(test_data_df, weights)), columns=[\"pred\"])\n",
    "\n",
    "submission_test = pandas.DataFrame(np.where(y_test.pred == 1, \">50K\", \"<=50K\"), columns=['guesses'])\n",
    "submission = {}\n",
    "submission['guesses'] = submission_test.guesses.values.tolist()\n",
    "\n",
    "with open('/Users/dleung/www/mlcompetition/test_submission.txt', 'w') as fp:\n",
    "    json.dump(submission, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stocGradAscent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-632cbe80ea85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Logistic Regression with SGD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstocGradAscent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvalidation_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifyVector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprintValidationResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_y_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_y_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'stocGradAscent' is not defined"
     ]
    }
   ],
   "source": [
    "# Logistic Regression with SGD\n",
    "weights, errors = stocGradAscent(train_data_df, train_y_df)\n",
    "validation_y_pred = classifyVector(validation_data_df, weights)\n",
    "printValidationResults(validation_y_pred, validation_y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Logistic Regression with minibatchSGD\n",
    "# Takes too long to run\n",
    "#weights, errors = minibatchStocGradAscent1(train_data_df, train_y_df)\n",
    "#validation_y_pred = classifyVector(validation_data_df, weights)\n",
    "#printValidationResults(validation_y_pred, validation_y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Support Vector Machines\n",
    "def selectJrand(i,m):\n",
    "    j=i\n",
    "    while (j==i):\n",
    "         j = int(random.uniform(0,m))\n",
    "    return j\n",
    "def clipAlpha(aj,H,L):\n",
    "    if aj > H: \n",
    "        aj = H\n",
    "    if L > aj:\n",
    "        aj = L\n",
    "    return aj    \n",
    "\n",
    "def smoSimple(dataMatIn, classLabels, C, toler, maxIter):\n",
    "    dataMatrix = np.mat(dataMatIn)\n",
    "    labelMat = np.mat(classLabels)\n",
    "    b = 0; m,n = np.shape(dataMatrix)\n",
    "    alphas = np.mat(np.zeros((m,1)))\n",
    "    iter = 0\n",
    "    while (iter < maxIter):\n",
    "        alphaPairsChanged = 0\n",
    "        for i in range(m):\n",
    "            fXi = (np.multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[i,:].T)).astype(np.float) + b\n",
    "            Ei = fXi - (labelMat[i]).astype(np.float)#if checks if an example violates KKT conditions\n",
    "            if ((np.sum(labelMat[i]*Ei) < -toler) and np.all(alphas[i] < C)) or ((np.sum(labelMat[i]*Ei) > toler) and np.all(alphas[i] > 0)):\n",
    "                j = selectJrand(i,m)\n",
    "                print(j)\n",
    "                fXj = (np.multiply(alphas,labelMat).T*(dataMatrix*dataMatrix[j,:].T)).astype(np.float) + b\n",
    "                Ej = fXj - (labelMat[j]).astype(np.float)\n",
    "                alphaIold = alphas[i].copy(); alphaJold = alphas[j].copy();\n",
    "                if (labelMat[i] != labelMat[j]):\n",
    "                    L = max(0, alphas[j] - alphas[i])\n",
    "                    H = min(C, C + alphas[j] - alphas[i])\n",
    "                else:\n",
    "                    L = max(0, alphas[j] + alphas[i] - C)\n",
    "                    H = min(C, alphas[j] + alphas[i])\n",
    "                if L==H: print \"L==H\"; continue\n",
    "                eta = 2.0 * dataMatrix[i,:]*dataMatrix[j,:].T - dataMatrix[i,:]*dataMatrix[i,:].T - dataMatrix[j,:]*dataMatrix[j,:].T\n",
    "                if eta >= 0: print \"eta>=0\"; continue\n",
    "                alphas[j] -= labelMat[j]*(Ei - Ej)/eta\n",
    "                alphas[j] = clipAlpha(alphas[j],H,L)\n",
    "                if (abs(alphas[j] - alphaJold) < 0.00001): print \"j not moving enough\"; continue\n",
    "                alphas[i] += labelMat[j]*labelMat[i]*(alphaJold - alphas[j])#update i by the same amount as j\n",
    "                                                                        #the update is in the oppostie direction\n",
    "                b1 = b - Ei- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[i,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[i,:]*dataMatrix[j,:].T\n",
    "                b2 = b - Ej- labelMat[i]*(alphas[i]-alphaIold)*dataMatrix[i,:]*dataMatrix[j,:].T - labelMat[j]*(alphas[j]-alphaJold)*dataMatrix[j,:]*dataMatrix[j,:].T\n",
    "                if (0 < alphas[i]) and (C > alphas[i]): b = b1\n",
    "                elif (0 < alphas[j]) and (C > alphas[j]): b = b2\n",
    "                else: b = (b1 + b2)/2.0\n",
    "                alphaPairsChanged += 1\n",
    "                print \"iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged)\n",
    "        if (alphaPairsChanged == 0): iter += 1\n",
    "        else: iter = 0\n",
    "        print \"iteration number: %d\" % iter\n",
    "    return b,alphas\n",
    "    \n",
    "class optStruct:\n",
    "    def __init__(self,dataMatIn, classLabels, C, toler):\n",
    "        self.X = dataMatIn\n",
    "        self.labelMat = classLabels\n",
    "        self.C = C\n",
    "        self.tol = toler\n",
    "        self.m = np.shape(dataMatIn)[0]\n",
    "        self.alphas = np.mat(np.zeros((self.m,1)))\n",
    "        self.b = 0\n",
    "        self.eCache = np.mat(np.zeros((self.m,2)))\n",
    "def calcEk(oS, k):\n",
    "    fXk = float(np.multiply(oS.alphas,oS.labelMat).T*(oS.X*oS.X[k,:].T)) + oS.b\n",
    "    Ek = fXk - float(oS.labelMat[k])\n",
    "    return Ek\n",
    "def selectJ(i, oS, Ei):\n",
    "    maxK = -1; maxDeltaE = 0; Ej = 0\n",
    "    oS.eCache[i] = [1,Ei]\n",
    "    validEcacheList = np.nonzero(oS.eCache[:,0].A)[0]\n",
    "    if (len(validEcacheList)) > 1:\n",
    "        for k in validEcacheList:\n",
    "            if k == i: continue\n",
    "            Ek = calcEk(oS, k)\n",
    "            deltaE = abs(Ei - Ek)\n",
    "            if (deltaE > maxDeltaE):\n",
    "                maxK = k; maxDeltaE = deltaE; Ej = Ek\n",
    "        return maxK, Ej\n",
    "    else:\n",
    "        j = selectJrand(i, oS.m)\n",
    "        Ej = calcEk(oS, j)\n",
    "    return j, Ej\n",
    "def updateEk(oS, k):\n",
    "    Ek = calcEk(oS, k)\n",
    "    oS.eCache[k] = [1,Ek]\n",
    "\n",
    "def innerL(i, oS, debug=False):\n",
    "    Ei = calcEk(oS, i)\n",
    "    if ((oS.labelMat[i]*Ei < -oS.tol) and (oS.alphas[i] < oS.C)) or ((oS.labelMat[i]*Ei > oS.tol) and (oS.alphas[i] > 0)):\n",
    "        j,Ej = selectJ(i, oS, Ei)\n",
    "        alphaIold = oS.alphas[i].copy(); alphaJold = oS.alphas[j].copy();\n",
    "        if (oS.labelMat[i] != oS.labelMat[j]):\n",
    "            L = max(0, oS.alphas[j] - oS.alphas[i])\n",
    "            H = min(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])\n",
    "        else:\n",
    "            L = max(0, oS.alphas[j] + oS.alphas[i] - oS.C)\n",
    "            H = min(oS.C, oS.alphas[j] + oS.alphas[i])\n",
    "        if L==H: \n",
    "            if debug:\n",
    "                print \"L==H\"\n",
    "            return 0\n",
    "        eta = 2.0 * oS.X[i,:]*oS.X[j,:].T - oS.X[i,:]*oS.X[i,:].T - oS.X[j,:]*oS.X[j,:].T\n",
    "        if eta >= 0: \n",
    "            if debug:\n",
    "                print \"eta>=0\"\n",
    "            return 0\n",
    "        oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)/eta\n",
    "        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L)\n",
    "        updateEk(oS, j)\n",
    "        \n",
    "        if (abs(oS.alphas[j] - alphaJold) < 0.00001):\n",
    "            if debug:\n",
    "                print \"j not moving enough\"\n",
    "            return 0\n",
    "        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])\n",
    "        updateEk(oS, i)\n",
    "        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[i,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[i,:]*oS.X[j,:].T\n",
    "        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.X[i,:]*oS.X[j,:].T - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.X[j,:]*oS.X[j,:].T\n",
    "        if (0 < oS.alphas[i]) and (oS.C > oS.alphas[i]): \n",
    "            oS.b = b1\n",
    "        elif (0 < oS.alphas[j]) and (oS.C > oS.alphas[j]): \n",
    "            oS.b = b2\n",
    "        else: \n",
    "            oS.b = (b1 + b2)/2.0\n",
    "        return 1\n",
    "    else: \n",
    "        return 0\n",
    "    \n",
    "def smoP(dataMatIn, classLabels, C, toler, maxIter, kTup=('lin', 0), debug=False):\n",
    "    oS = optStruct(np.mat(dataMatIn),np.mat(classLabels),C,toler)\n",
    "    iter = 0\n",
    "    entireSet = True; alphaPairsChanged = 0\n",
    "    while (iter < maxIter) and ((alphaPairsChanged > 0) or (entireSet)):\n",
    "        print(iter)\n",
    "        alphaPairsChanged = 0\n",
    "        if entireSet:\n",
    "            for i in range(oS.m):\n",
    "                alphaPairsChanged += innerL(i,oS, debug)\n",
    "            print \"fullSet, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged)\n",
    "            iter += 1\n",
    "        else:\n",
    "            nonBoundIs = np.nonzero((oS.alphas.A > 0) * (oS.alphas.A < C))[0]\n",
    "            for i in nonBoundIs:\n",
    "                alphaPairsChanged += innerL(i,oS, debug)\n",
    "                if debug:\n",
    "                    print \"non-bound, iter: %d i:%d, pairs changed %d\" % (iter,i,alphaPairsChanged)\n",
    "            iter += 1\n",
    "        if entireSet: entireSet = False\n",
    "        elif (alphaPairsChanged == 0): entireSet = True\n",
    "        if debug:\n",
    "            print \"iteration number: %d\" % iter\n",
    "    return oS.b,oS.alphas\n",
    "\n",
    "def calcWs(alphas,dataArr,classLabels):\n",
    "    X = np.mat(dataArr)\n",
    "    labelMat = np.mat(classLabels)\n",
    "    m,n = np.shape(X)\n",
    "    w = np.zeros((n,1))\n",
    "    for i in range(m):\n",
    "        w += np.multiply(alphas[i]*labelMat[i],X[i,:].T)\n",
    "    return w\n",
    "\n",
    "def classifySvm(data, weights, b):\n",
    "    sig_y = np.mat(data) * np.mat(ws) + b\n",
    "    sig_y_df = pandas.DataFrame(np.asarray(sig_y), columns=['y_pred'])\n",
    "    return pandas.DataFrame(np.where(sig_y_df['y_pred'] >=  0, 1, 0), columns=['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-c3d9ff6f0109>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malphas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoP\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x_svm_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_svm_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalcWs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_x_svm_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrain_y_svm_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-307d3af25544>\u001b[0m in \u001b[0;36msmoP\u001b[0;34m(dataMatIn, classLabels, C, toler, maxIter, kTup, debug)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mentireSet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m                 \u001b[0malphaPairsChanged\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0minnerL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0;32mprint\u001b[0m \u001b[0;34m\"fullSet, iter: %d i:%d, pairs changed %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0malphaPairsChanged\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0miter\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-307d3af25544>\u001b[0m in \u001b[0;36minnerL\u001b[0;34m(i, oS, debug)\u001b[0m\n\u001b[1;32m     92\u001b[0m     \u001b[0mEi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalcEk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabelMat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mEi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabelMat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mEi\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mEj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselectJ\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m         \u001b[0malphaIold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0malphaJold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabelMat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabelMat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-307d3af25544>\u001b[0m in \u001b[0;36mselectJ\u001b[0;34m(i, oS, Ei)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalidEcacheList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mEk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalcEk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mdeltaE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mEk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdeltaE\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxDeltaE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-307d3af25544>\u001b[0m in \u001b[0;36mcalcEk\u001b[0;34m(oS, k)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meCache\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcalcEk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m     \u001b[0mfXk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malphas\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabelMat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m     \u001b[0mEk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfXk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabelMat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mEk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/site-packages/numpy/matrixlib/defmatrix.pyc\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0;31m# This promotes 1-D vectors to row vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__rmul__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_x_svm_df = train_data_df.copy()\n",
    "# SVM likes solutions with labesl -1 and 1\n",
    "train_y_svm_df = pandas.DataFrame(np.where(train_y_df.label == 0, -1, 1), columns=['label'])\n",
    "\n",
    "start = time.time()\n",
    "b,alphas = smoP(train_x_svm_df, train_y_svm_df, 0.6, 0.001, 40)\n",
    "end = time.time()\n",
    "ws = calcWs(alphas,train_x_svm_df,train_y_svm_df)\n",
    "\n",
    "m, n = np.shape(alphas[alphas>0])\n",
    "print('Number of support vectors found: %02f' % n)\n",
    "print('Time to train: %02f secs' % (end-start))\n",
    "\n",
    "validation_y_svm_df = classifySvm(validation_data_df, ws, b)\n",
    "printValidationResults(validation_y_svm_df, validation_y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/svm/base.py:514: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y_ = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-8441621b8d2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mvalidation_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#SKLearn validations\n",
    "\n",
    "#SVM\n",
    "from sklearn import svm\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(train_data_df, train_y_df) \n",
    "\n",
    "validation_y_pred = clf.predict(validation_data_df)\n",
    "\n",
    "printValidationResults(validation_y_pred, validation_y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========validation results============\n",
      "correct: 5558.000000\n",
      "total: 6511.000000\n",
      "% correct: 0.853632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/sklearn/utils/validation.py:515: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "# Scikitlearn Logistic Regression\n",
    "\n",
    "from sklearn import linear_model\n",
    "\n",
    "clf = linear_model.LogisticRegression(C=1.0, penalty='l1', tol=1e-6)\n",
    "clf.fit(train_data_df, train_y_df) \n",
    "\n",
    "validation_y_pred = clf.predict(validation_data_df)\n",
    "\n",
    "printValidationResults(validation_y_pred, validation_y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
